{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0.5022, 0.9179, 0.9019, 0.5201],\n        [0.0594, 0.0461, 0.4451, 0.2992]])"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))\n",
    "X = torch.rand(2, 4)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.0587],\n        [ 0.0592]], grad_fn=<AddmmBackward0>)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(X)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "Sequential(\n  (0): Linear(in_features=4, out_features=8, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=8, out_features=1, bias=True)\n)"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([1., 2., 3.]), tensor([1.2173, 0.7999], grad_fn=<ViewBackward0>))"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 定义一个简单的线性层\n",
    "class LinearLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(LinearLayer, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "# 创建线性层实例\n",
    "linear_layer = LinearLayer(3, 2)\n",
    "# 输入数据\n",
    "input_data = torch.tensor([1.0, 2.0, 3.0])\n",
    "# 前向传播\n",
    "output = linear_layer(input_data)\n",
    "input_data, output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "# 获取权重参数\n",
    "weights = linear_layer.linear.weight.data\n",
    "print(weights.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([6])\n",
      "tensor([1, 2, 3, 4, 5, 6])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(x.shape)  # torch.Size([2, 3])\n",
    "\n",
    "x_flatten = x.flatten()\n",
    "print(x_flatten.shape)  # torch.Size([6])\n",
    "print(x_flatten)  # tensor([1, 2, 3, 4, 5, 6])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),\n",
    "    nn.Linear(120, 84), nn.Sigmoid(),\n",
    "    nn.Linear(84, 10))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "Sequential(\n  (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n  (1): Sigmoid()\n  (2): AvgPool2d(kernel_size=2, stride=2, padding=0)\n  (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n  (4): Sigmoid()\n  (5): AvgPool2d(kernel_size=2, stride=2, padding=0)\n  (6): Flatten(start_dim=1, end_dim=-1)\n  (7): Linear(in_features=400, out_features=120, bias=True)\n  (8): Sigmoid()\n  (9): Linear(in_features=120, out_features=84, bias=True)\n  (10): Sigmoid()\n  (11): Linear(in_features=84, out_features=10, bias=True)\n)"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output shape: \t torch.Size([1, 6, 28, 28])\n",
      "Sigmoid output shape: \t torch.Size([1, 6, 28, 28])\n",
      "AvgPool2d output shape: \t torch.Size([1, 6, 14, 14])\n",
      "Conv2d output shape: \t torch.Size([1, 16, 10, 10])\n",
      "Sigmoid output shape: \t torch.Size([1, 16, 10, 10])\n",
      "AvgPool2d output shape: \t torch.Size([1, 16, 5, 5])\n",
      "Flatten output shape: \t torch.Size([1, 400])\n",
      "Linear output shape: \t torch.Size([1, 120])\n",
      "Sigmoid output shape: \t torch.Size([1, 120])\n",
      "Linear output shape: \t torch.Size([1, 84])\n",
      "Sigmoid output shape: \t torch.Size([1, 84])\n",
      "Linear output shape: \t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(size=(1, 1, 28, 28), dtype=torch.float32)\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__, 'output shape: \\t', X.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[-1.0783, -0.1198,  0.8387],\n          [-1.5575, -1.0783, -0.5990],\n          [-0.5990,  0.3594,  1.3179],\n          [-0.1198,  0.8387,  1.7971]]]])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With Learnable Parameters‘\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "m = nn.BatchNorm2d(1)\n",
    "# Without Learnable Parameters\n",
    "m = nn.BatchNorm2d(1, affine=False)\n",
    "input = torch.tensor([[10, 20, 30],\n",
    "                      [5, 10, 15],\n",
    "                      [15, 25, 35],\n",
    "                      [20, 30, 40]],dtype=torch.float32)\n",
    "input=torch.reshape(input,(1,1,4,3))\n",
    "\n",
    "output = m(input)\n",
    "output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[[ 2.6192e-01,  6.4690e-02, -7.6080e-01,  ..., -1.4802e+00,\n            1.6848e+00,  8.8658e-01],\n          [-3.8446e-01, -9.5117e-04,  1.9758e+00,  ...,  9.1725e-01,\n            6.4250e-01, -9.1413e-01],\n          [-1.3996e+00,  1.2922e+00, -2.6763e-01,  ...,  1.4828e+00,\n            8.6064e-01,  1.0947e+00],\n          ...,\n          [ 1.0388e+00,  1.0541e+00, -1.3746e+00,  ...,  5.5614e-03,\n            1.0735e+00,  5.7630e-01],\n          [-3.6401e-01, -1.0425e+00,  7.3467e-01,  ..., -6.9850e-02,\n           -1.5262e+00, -5.4492e-01],\n          [-1.3980e+00, -8.7290e-01, -1.2957e-01,  ...,  3.7508e-01,\n           -8.7559e-01,  4.5072e-02]],\n\n         [[ 1.2523e+00,  2.4194e+00, -6.8633e-01,  ...,  6.6588e-01,\n            4.3631e-01,  1.9580e-01],\n          [-9.4195e-02, -1.8806e+00, -1.7267e+00,  ...,  4.7139e-02,\n           -7.2491e-01, -2.7867e-01],\n          [ 1.3062e+00, -9.9480e-01, -5.9085e-01,  ...,  1.3252e+00,\n            1.2739e+00,  1.5733e+00],\n          ...,\n          [-4.0267e-01,  7.8295e-01,  4.2335e-01,  ..., -8.7530e-01,\n           -1.9038e-01,  9.2110e-01],\n          [-6.2984e-01,  1.5557e-01,  4.1887e-01,  ...,  1.2948e-01,\n            1.7086e+00,  1.0025e+00],\n          [-9.9479e-01,  9.3895e-01, -9.5695e-01,  ...,  7.8978e-01,\n           -5.2946e-01,  9.4533e-01]],\n\n         [[ 1.2806e+00,  4.9552e-01,  2.2983e-01,  ...,  3.0622e-01,\n           -1.1454e+00, -9.9876e-01],\n          [-1.3210e+00,  7.4680e-01, -8.6966e-01,  ...,  5.6468e-01,\n           -2.0284e+00, -6.6334e-01],\n          [ 1.5119e+00,  4.5369e-01, -1.1531e+00,  ..., -1.1671e+00,\n            1.0257e+00,  8.9522e-01],\n          ...,\n          [ 3.8568e-02, -8.2581e-01, -2.6858e-01,  ..., -8.6918e-01,\n            6.7893e-01, -1.0752e+00],\n          [ 4.4635e-01, -1.8822e-01,  1.6617e+00,  ..., -4.6913e-01,\n            5.6658e-01,  1.1513e+00],\n          [ 6.2807e-01, -1.5148e-01,  8.0307e-01,  ..., -3.7506e-01,\n            1.0645e+00, -1.0862e+00]],\n\n         ...,\n\n         [[-3.8794e-01, -5.0312e-01, -1.2334e-01,  ...,  2.4409e-01,\n            5.0431e-01,  3.2025e-01],\n          [-6.3429e-01, -7.6045e-01, -1.4577e+00,  ...,  9.4682e-01,\n           -8.7695e-01, -9.3244e-01],\n          [ 1.1044e+00,  1.8632e+00, -2.6281e+00,  ..., -1.3075e+00,\n            1.1241e+00, -3.4257e-01],\n          ...,\n          [ 5.1506e-01,  2.8158e-01,  1.1290e+00,  ..., -1.0471e+00,\n           -4.3605e-01,  6.5916e-01],\n          [ 6.3167e-01, -4.3706e-01, -2.3078e-01,  ..., -8.8195e-01,\n            1.0178e+00,  1.4172e+00],\n          [ 1.5311e+00, -3.0074e-01,  1.0206e+00,  ..., -1.0761e-01,\n           -2.7055e-01, -9.9181e-02]],\n\n         [[ 1.2042e-01, -1.3475e+00,  7.7346e-02,  ..., -1.0253e+00,\n           -7.7301e-01,  1.2193e+00],\n          [ 1.0568e+00,  2.0018e+00,  8.8083e-01,  ...,  1.5575e+00,\n           -1.2842e+00,  1.0375e-01],\n          [-7.8112e-01, -6.2825e-01,  5.5944e-01,  ..., -5.2523e-01,\n           -6.4832e-01,  1.6703e+00],\n          ...,\n          [-7.4544e-01, -1.0150e-01,  1.3814e+00,  ..., -1.6413e+00,\n            6.8288e-01, -1.4675e+00],\n          [-1.0374e+00, -8.0320e-01,  1.2670e+00,  ...,  1.7806e+00,\n            1.8664e+00, -1.0584e+00],\n          [ 1.2562e+00,  5.8935e-01, -1.1888e-01,  ..., -9.8249e-01,\n            4.3561e-01, -1.1322e+00]],\n\n         [[-1.2782e+00, -4.7010e-01, -1.0837e+00,  ..., -1.4677e+00,\n            1.2476e+00,  1.3034e-01],\n          [ 8.9789e-01,  4.1009e-01, -2.2634e+00,  ..., -2.1001e+00,\n           -7.7101e-01,  2.0659e+00],\n          [ 1.5073e+00,  3.5970e-01,  1.2852e-01,  ..., -1.3015e-02,\n           -5.3662e-01,  6.1443e-02],\n          ...,\n          [-5.0319e-02,  1.4740e+00, -2.8284e+00,  ..., -5.0881e-01,\n            1.9565e+00,  1.2448e+00],\n          [-1.1068e+00,  5.2244e-02,  5.5705e-01,  ..., -8.6428e-01,\n            5.6913e-01,  3.1917e-01],\n          [ 1.4535e-01, -5.1687e-01,  6.9446e-01,  ...,  7.3599e-02,\n            5.5859e-01,  2.1808e-02]]],\n\n\n        [[[ 6.9585e-01, -2.7003e-01, -9.2515e-01,  ...,  4.2252e-01,\n           -1.6830e-02, -1.5895e+00],\n          [ 5.6593e-01, -1.2041e+00,  7.2715e-02,  ...,  4.1017e-01,\n           -2.9598e-01, -1.5280e+00],\n          [ 2.6746e+00, -1.3315e+00, -5.4526e-01,  ...,  5.3577e-01,\n            1.3729e-01,  5.2729e-01],\n          ...,\n          [ 8.4646e-01, -9.3671e-01, -2.0898e+00,  ..., -7.9211e-01,\n            1.3635e-01, -4.7190e-01],\n          [-1.1627e-01,  1.1589e+00,  8.6064e-01,  ..., -1.0615e+00,\n            8.9260e-01,  2.3505e+00],\n          [-1.6681e+00,  4.2012e-01,  1.2857e+00,  ...,  3.2980e+00,\n           -7.2573e-01,  1.0122e+00]],\n\n         [[ 2.9770e-01,  3.5760e-01, -3.1742e-01,  ..., -9.0886e-01,\n           -1.5850e+00, -2.6333e-01],\n          [-7.1054e-01, -2.8869e-01, -8.9456e-01,  ..., -6.2480e-01,\n           -5.5546e-01, -7.6908e-01],\n          [-4.3741e-01, -3.3472e-01, -1.6972e+00,  ..., -6.2507e-01,\n            1.5186e+00, -1.5704e+00],\n          ...,\n          [-1.1014e+00, -2.9358e-01, -6.3101e-01,  ..., -3.7705e-03,\n           -6.4022e-01, -6.6015e-01],\n          [ 5.9483e-01,  1.0146e+00,  1.1553e+00,  ..., -1.7154e+00,\n            6.2659e-01,  5.0924e-01],\n          [-8.1869e-01, -4.0681e-01,  6.0442e-01,  ..., -9.3077e-01,\n            1.7151e+00,  3.1591e-01]],\n\n         [[-5.6483e-01,  2.5019e-01, -1.1462e+00,  ..., -8.3507e-01,\n            2.0353e-01, -2.0886e-01],\n          [-1.7224e+00, -1.2153e+00,  1.5111e+00,  ..., -2.3419e-01,\n            6.9325e-01, -4.7320e-03],\n          [-3.8800e-02,  3.7207e-01, -1.0514e+00,  ..., -1.1956e+00,\n            1.4739e+00,  1.1294e+00],\n          ...,\n          [-1.1798e+00, -1.3643e+00,  1.9467e+00,  ...,  1.1745e+00,\n            2.7056e-01, -1.4955e+00],\n          [ 1.1411e+00, -3.6705e-01, -7.0306e-01,  ..., -2.1392e+00,\n           -3.2108e-01,  1.4094e+00],\n          [ 1.4789e+00,  4.7640e-01, -4.1402e-01,  ...,  1.5900e+00,\n            4.0508e-01, -4.4327e-01]],\n\n         ...,\n\n         [[-1.2044e+00,  2.1920e+00, -1.0863e+00,  ..., -1.1492e-02,\n           -4.3747e-01, -1.7582e+00],\n          [ 8.5925e-02,  1.5667e+00, -3.3624e-01,  ...,  6.0548e-01,\n           -2.5966e-01,  2.6170e-01],\n          [-2.2740e-01,  2.8201e+00,  1.6496e-01,  ..., -1.0002e+00,\n           -6.6116e-01,  1.9656e-05],\n          ...,\n          [ 6.1853e-01, -1.4571e+00, -3.3776e-01,  ..., -9.7844e-02,\n            4.3766e-01,  1.1795e+00],\n          [ 9.5643e-01, -7.7383e-02,  2.2545e-01,  ..., -2.2958e+00,\n            5.0849e-01,  4.7978e-02],\n          [ 1.5650e+00, -1.9881e-01, -4.2136e-01,  ..., -6.3483e-01,\n           -7.7244e-01, -1.4042e-01]],\n\n         [[-1.1223e+00,  4.1518e-01, -1.4016e+00,  ..., -3.0798e+00,\n            1.3103e-01, -7.3403e-01],\n          [-4.3980e-01,  1.1920e+00, -2.4449e-01,  ...,  1.7031e-01,\n           -7.3571e-01, -8.7067e-01],\n          [-5.2098e-01,  2.1361e+00, -8.5916e-01,  ...,  4.0558e-01,\n            4.9985e-01,  2.8092e+00],\n          ...,\n          [-1.2483e+00, -1.4287e-01, -7.5601e-01,  ...,  2.4204e+00,\n            2.1560e+00, -4.8604e-01],\n          [ 9.2524e-01, -1.3791e+00,  2.1351e-01,  ..., -1.4451e+00,\n            5.0445e-01,  6.6025e-01],\n          [-1.4653e+00,  5.4505e-01, -5.2663e-01,  ...,  1.0884e+00,\n            4.3883e-02, -5.9397e-01]],\n\n         [[-2.5332e-01, -1.6439e+00, -5.4530e-01,  ..., -1.2793e+00,\n           -7.8369e-02,  4.4654e-01],\n          [-6.2087e-01,  7.4790e-01, -2.1286e+00,  ...,  5.6851e-01,\n            1.0672e+00, -9.6921e-01],\n          [ 1.4333e+00, -6.1756e-01,  1.8351e+00,  ..., -1.1619e+00,\n            1.0963e+00,  1.4186e+00],\n          ...,\n          [-2.9513e-01, -2.6995e-01, -6.4866e-01,  ..., -7.7703e-01,\n           -2.1514e-01,  2.5140e+00],\n          [ 1.6132e-01,  6.2341e-01, -5.9848e-01,  ..., -9.4603e-01,\n           -2.0057e+00,  6.5471e-01],\n          [-2.1170e+00,  1.4862e-01, -2.8260e-01,  ..., -2.0692e+00,\n           -9.9235e-01,  6.9184e-01]]],\n\n\n        [[[-3.0155e-01,  1.9192e+00,  1.8553e+00,  ...,  6.6005e-01,\n            1.3811e+00, -5.6789e-01],\n          [ 7.4226e-01,  4.5442e-01, -7.2806e-02,  ...,  4.2637e-01,\n            3.5370e-01,  3.1531e-01],\n          [ 1.8310e+00, -2.4370e+00,  2.6834e+00,  ..., -8.7931e-02,\n           -8.2171e-01, -8.2727e-01],\n          ...,\n          [-1.7159e+00,  4.6954e-03,  5.6937e-01,  ...,  2.6137e-02,\n            8.7505e-02,  1.6594e-01],\n          [ 1.3616e+00, -1.2854e+00,  1.3295e+00,  ..., -3.5297e-01,\n            2.5803e-01, -1.7946e+00],\n          [ 5.2284e-01, -9.5205e-01,  8.3004e-01,  ...,  1.4647e+00,\n           -5.4447e-01, -1.0186e+00]],\n\n         [[ 2.2142e-01, -8.9848e-01, -1.6971e-01,  ...,  8.5617e-01,\n            8.9860e-01,  7.0703e-01],\n          [ 1.6442e+00, -7.5663e-01, -3.8800e-02,  ..., -1.0473e+00,\n            7.1582e-01, -6.1447e-01],\n          [-2.3894e-01, -5.6540e-01, -1.5719e-01,  ..., -4.7056e-01,\n            3.9066e-01,  7.9980e-01],\n          ...,\n          [ 1.3749e+00,  3.3231e-01,  4.0237e+00,  ..., -8.7174e-01,\n           -1.0350e+00,  1.1585e+00],\n          [-4.6325e-01,  1.1722e+00, -1.7111e+00,  ..., -6.8137e-01,\n           -1.3699e+00,  1.1959e-01],\n          [ 6.1141e-01, -1.4867e+00, -2.2477e-01,  ..., -1.9803e+00,\n           -8.4253e-02,  1.3818e+00]],\n\n         [[ 1.2886e+00, -5.3415e-01,  1.8718e+00,  ..., -2.5723e-02,\n            3.6976e-01, -1.3897e+00],\n          [-6.6995e-02,  4.9552e-01,  1.0056e+00,  ..., -7.4934e-01,\n            4.1573e-01, -7.4876e-01],\n          [-1.1626e+00, -8.6581e-01,  3.0458e-01,  ...,  6.9665e-01,\n           -6.9572e-02, -1.6511e+00],\n          ...,\n          [ 2.0350e+00,  7.9714e-01, -6.0818e-01,  ..., -4.5603e-01,\n            1.7419e+00, -4.7423e-01],\n          [ 2.6784e-01,  1.2732e+00, -1.4815e+00,  ..., -1.9302e-01,\n            1.5047e-01,  4.7536e-01],\n          [-3.4844e-01, -3.5812e-01, -3.4188e-02,  ..., -1.0509e+00,\n            1.3401e+00,  6.7939e-02]],\n\n         ...,\n\n         [[-2.7700e-01,  1.8001e-01,  5.9249e-01,  ...,  1.5260e+00,\n            5.9238e-01,  2.0829e-01],\n          [ 9.2571e-01, -1.4071e+00,  5.0896e-01,  ..., -4.8588e-01,\n           -5.5869e-02, -2.9062e+00],\n          [ 5.5508e-01,  1.4388e+00,  2.6005e-01,  ..., -2.7056e-01,\n            7.4822e-01, -2.9926e-01],\n          ...,\n          [ 1.5173e+00,  1.7794e+00, -1.3418e+00,  ...,  3.1716e-01,\n           -1.6316e-02,  5.6441e-01],\n          [ 1.0859e+00,  5.6643e-01, -4.2942e-01,  ..., -1.0562e+00,\n            2.1345e-01, -8.4469e-01],\n          [ 6.0567e-01, -1.8528e+00,  7.3631e-01,  ...,  2.3062e+00,\n            2.6521e+00, -1.8499e+00]],\n\n         [[-8.8900e-01, -4.4036e-01,  4.1025e-01,  ...,  5.4880e-01,\n           -7.2100e-02, -9.2439e-01],\n          [ 1.7367e-01,  3.4174e-01, -2.2155e+00,  ...,  3.8522e-02,\n            1.5505e+00, -7.8569e-01],\n          [ 1.3149e-01, -4.7138e-01, -4.5762e-01,  ...,  6.4449e-01,\n            1.5189e+00,  2.0979e-01],\n          ...,\n          [-2.9253e+00, -6.5832e-01,  7.4994e-01,  ..., -1.5166e+00,\n           -8.9400e-01,  1.0563e+00],\n          [-6.2990e-01, -3.1267e-01, -7.3424e-01,  ...,  1.5046e+00,\n           -1.0717e+00, -1.1944e+00],\n          [ 1.3980e+00,  1.1087e+00, -8.9459e-01,  ...,  2.6825e-01,\n           -3.3598e-01, -5.9589e-01]],\n\n         [[ 2.0088e+00, -8.1182e-01,  2.2882e-01,  ...,  7.6070e-01,\n           -5.1748e-01, -2.3853e+00],\n          [-1.0284e+00, -6.3332e-02, -2.4927e+00,  ..., -3.3655e-01,\n            1.7459e+00, -1.0833e+00],\n          [-6.2857e-01, -2.9637e-01,  2.6213e-02,  ..., -4.4312e-01,\n            5.6804e-01, -8.5654e-02],\n          ...,\n          [ 5.3689e-01, -9.5092e-01, -1.1340e+00,  ...,  2.8936e-01,\n           -1.0847e+00,  9.9867e-01],\n          [-1.5336e+00, -4.1855e-01, -1.2432e+00,  ..., -8.1111e-01,\n           -1.9339e+00, -8.9019e-01],\n          [-3.8051e-01, -5.4552e-01, -2.0817e-01,  ...,  2.1935e+00,\n           -1.7174e-01,  6.5269e-01]]],\n\n\n        ...,\n\n\n        [[[ 4.2297e-01, -7.4286e-01, -7.2464e-01,  ...,  1.1701e+00,\n           -6.3917e-02,  1.4578e+00],\n          [ 2.4060e-02,  4.1008e-01,  7.3211e-01,  ...,  4.9818e-01,\n           -4.4868e-01, -1.7666e-01],\n          [-1.4913e+00,  1.3999e+00, -1.8059e-01,  ..., -1.4557e+00,\n           -1.1057e-01, -1.4516e+00],\n          ...,\n          [ 2.3512e+00,  7.6303e-01,  5.4537e-01,  ...,  1.0285e+00,\n            2.0647e+00, -1.3286e+00],\n          [-9.6275e-01, -5.2332e-01,  2.3766e+00,  ..., -1.4839e+00,\n            1.4939e-01, -7.4884e-01],\n          [-1.0512e-01, -1.4793e+00,  2.8077e-01,  ...,  7.9936e-01,\n           -7.2843e-01, -1.6240e-02]],\n\n         [[-1.7885e-01,  1.9184e-01,  1.1314e+00,  ..., -8.7350e-01,\n            1.3892e+00, -2.0832e+00],\n          [-3.8846e-01, -3.8389e-01, -1.8643e+00,  ..., -9.4026e-01,\n            1.2281e-02, -6.1434e-01],\n          [ 4.7152e-01,  1.0641e+00,  3.5609e-01,  ..., -4.3855e-02,\n            2.9560e-01, -1.2086e+00],\n          ...,\n          [ 4.4365e-01,  2.3595e-01,  2.6457e-01,  ..., -4.9401e-01,\n           -1.0587e+00,  7.9820e-01],\n          [ 3.0661e-01,  1.4274e+00,  4.9911e-01,  ..., -2.8366e-01,\n           -6.6848e-01, -1.0075e+00],\n          [ 9.8575e-01,  9.4132e-01, -7.1370e-01,  ...,  4.1248e-01,\n            1.2387e+00,  5.1078e-01]],\n\n         [[ 1.0702e+00,  1.7824e+00,  2.8094e-02,  ..., -1.8771e+00,\n           -1.6768e+00,  4.6811e-01],\n          [-2.6062e-01, -3.8892e-01,  2.3185e-01,  ..., -6.8145e-01,\n            2.1171e-01,  2.1466e-01],\n          [-8.9788e-01, -6.7550e-01, -3.7427e-01,  ..., -2.8999e+00,\n            4.0107e-01, -2.2602e+00],\n          ...,\n          [-7.8424e-01, -1.5146e+00, -4.3299e-01,  ..., -1.8856e+00,\n           -3.8072e-01,  3.0801e+00],\n          [ 8.4721e-01, -8.8298e-01, -1.2671e+00,  ..., -2.8711e-01,\n            3.4505e-01,  3.0755e-01],\n          [-2.2611e-01, -4.2009e-03, -7.0256e-01,  ..., -1.7283e+00,\n            1.8711e+00, -6.5763e-01]],\n\n         ...,\n\n         [[ 7.2142e-01, -2.7922e+00, -1.2343e+00,  ..., -4.3875e-01,\n            9.4280e-01, -3.3360e-02],\n          [ 1.6129e+00,  7.6169e-01,  3.3277e-01,  ..., -1.4980e+00,\n            2.6293e-01, -2.6963e-01],\n          [-4.7531e-01, -1.0567e+00,  3.0340e-01,  ..., -1.0544e+00,\n           -2.3373e+00,  1.7295e+00],\n          ...,\n          [ 7.8291e-01,  8.6769e-01,  3.9141e-01,  ..., -6.8627e-01,\n            2.6934e+00,  9.7201e-01],\n          [ 5.4418e-01, -5.5483e-01, -4.7967e-01,  ..., -1.4807e+00,\n           -7.0526e-01,  1.6286e+00],\n          [ 1.9523e+00,  5.0339e-01,  1.2903e+00,  ...,  1.9825e+00,\n           -6.4289e-01,  2.1224e+00]],\n\n         [[-1.6257e-01,  9.3370e-01,  8.2376e-01,  ...,  1.4502e+00,\n            5.9057e-01,  8.9196e-01],\n          [ 1.1112e+00, -2.1891e+00, -2.2357e-01,  ...,  8.8000e-01,\n            6.9797e-01,  1.3200e+00],\n          [ 1.0778e+00, -1.4243e+00,  4.0524e-01,  ..., -1.4664e+00,\n           -1.5250e-01, -1.3709e+00],\n          ...,\n          [-4.2817e-01, -1.6408e+00,  1.6698e-01,  ...,  1.1176e+00,\n           -6.0183e-01, -8.9637e-01],\n          [ 1.6492e-01, -2.7048e-01, -1.1075e+00,  ...,  1.1301e+00,\n           -7.5692e-01, -5.1879e-01],\n          [ 7.9271e-01,  8.7967e-01, -3.1413e-01,  ..., -8.8104e-01,\n           -7.0753e-01,  3.0396e-01]],\n\n         [[ 1.8879e-01, -6.3987e-01, -2.0691e-01,  ...,  1.3245e+00,\n            1.1234e+00, -8.1305e-01],\n          [-1.6686e+00,  2.6882e+00,  2.0840e-01,  ..., -1.5290e+00,\n           -2.4685e-01,  1.0481e+00],\n          [ 1.8953e+00, -1.0922e+00,  9.0382e-01,  ...,  2.4226e+00,\n            8.3402e-01,  6.3013e-01],\n          ...,\n          [ 5.8183e-01,  1.3803e-01,  6.6229e-01,  ..., -1.1724e+00,\n           -6.7182e-01,  5.7201e-01],\n          [-5.5512e-01,  3.4797e-01,  1.7398e-01,  ...,  3.4182e-01,\n            1.4444e+00, -8.0391e-01],\n          [ 6.5815e-01,  9.4485e-01,  5.2782e-01,  ...,  3.5806e-01,\n            1.2222e-01, -9.9437e-01]]],\n\n\n        [[[-1.5341e+00, -1.1511e+00,  1.9335e-01,  ...,  1.9284e-01,\n            1.7481e-01, -8.0497e-01],\n          [ 2.0031e+00,  2.0346e-01, -8.1789e-01,  ...,  6.7870e-01,\n            2.0195e+00, -5.0134e-01],\n          [-4.5944e-01,  1.0581e+00,  2.0925e-01,  ..., -3.0031e-01,\n           -5.2248e-01,  5.7010e-01],\n          ...,\n          [-1.4611e+00,  2.0981e+00, -7.3779e-01,  ...,  5.7546e-01,\n            1.7981e+00, -7.6552e-01],\n          [-1.7670e-01,  5.9052e-01, -5.2537e-01,  ...,  1.7006e-01,\n            6.1954e-01, -1.2585e+00],\n          [ 6.3603e-02, -2.5924e-01, -4.1127e-01,  ...,  6.0572e-01,\n            3.6506e-01,  5.7545e-01]],\n\n         [[ 1.0729e+00, -1.3574e-01,  1.8606e+00,  ..., -3.8970e-01,\n           -1.1955e+00,  1.1192e+00],\n          [ 6.4624e-01,  1.6463e+00, -7.2174e-01,  ...,  7.0588e-01,\n           -4.5278e-01,  1.3298e+00],\n          [ 3.8187e-01,  1.3211e+00,  1.0936e+00,  ...,  1.6682e+00,\n           -7.2064e-01, -1.1020e+00],\n          ...,\n          [ 2.2226e-01,  3.3486e-01, -6.9914e-01,  ...,  4.2486e-02,\n           -1.3477e-01,  2.6949e-01],\n          [ 6.4751e-01, -4.4148e-01,  1.5138e-01,  ...,  1.9246e+00,\n            9.6048e-01, -8.5665e-01],\n          [-2.4881e-01,  3.0604e-01,  1.9452e+00,  ...,  7.0136e-01,\n           -9.2185e-01,  2.9466e-01]],\n\n         [[ 5.7040e-02, -7.7039e-02,  1.6539e-01,  ...,  3.9700e-01,\n            1.2309e+00, -2.3411e+00],\n          [ 1.5281e+00,  2.3719e-01, -1.9747e-02,  ...,  2.1453e-01,\n            9.6682e-01, -1.0970e+00],\n          [-6.1419e-01, -9.9660e-02, -7.9049e-01,  ..., -1.0085e+00,\n           -1.2112e-01, -9.5343e-01],\n          ...,\n          [-1.1069e+00, -6.3058e-01,  1.2939e+00,  ..., -5.1064e-01,\n            2.0871e+00,  2.4605e-01],\n          [-1.9403e-01, -5.8723e-02,  2.6071e-01,  ...,  6.0663e-01,\n            9.2814e-01,  1.7211e+00],\n          [ 3.2106e-01,  2.4349e-02,  4.4893e-01,  ...,  2.4504e+00,\n           -8.6490e-01, -8.2160e-01]],\n\n         ...,\n\n         [[ 6.2139e-01, -4.2455e-02,  1.8882e+00,  ...,  6.1018e-01,\n           -6.2698e-01, -2.5489e-01],\n          [-9.7995e-01,  8.5141e-01,  4.4307e-01,  ...,  7.4972e-02,\n            1.0327e-01,  1.2727e+00],\n          [ 9.9699e-01, -1.4133e+00,  3.2479e-01,  ..., -9.6234e-01,\n            2.9365e-01,  1.7533e-01],\n          ...,\n          [ 1.0932e-01, -4.4100e-01, -1.0336e+00,  ..., -5.5242e-01,\n           -1.0757e+00,  8.6810e-01],\n          [-8.6131e-01, -1.2566e+00,  1.1896e+00,  ..., -1.8364e-01,\n            5.5518e-01, -7.1221e-01],\n          [ 4.1937e-01, -1.2488e+00, -1.1778e+00,  ...,  3.5103e-01,\n           -9.3351e-01,  1.1489e-01]],\n\n         [[-8.3592e-01, -8.9148e-01,  4.3201e-01,  ..., -4.0824e-01,\n           -1.2504e+00,  1.1265e+00],\n          [ 2.1431e-01,  8.3367e-01,  1.2513e+00,  ..., -2.5839e-01,\n           -1.5813e+00,  7.7051e-01],\n          [ 2.1335e+00, -9.5544e-01,  8.6195e-01,  ...,  1.3179e+00,\n            7.4878e-01, -3.4708e-01],\n          ...,\n          [-1.1176e-02,  7.1643e-01, -2.3522e-01,  ...,  1.3218e-01,\n            1.0059e+00, -9.6298e-01],\n          [-3.4490e-01,  3.0352e-01, -5.5953e-01,  ..., -3.2104e-01,\n           -2.8019e-01,  1.0434e-01],\n          [ 3.2062e+00,  1.3993e+00, -6.1936e-01,  ...,  9.1966e-01,\n           -1.0526e+00, -5.7622e-01]],\n\n         [[ 3.1891e-01, -8.1085e-01,  5.8998e-01,  ..., -7.1279e-01,\n           -2.0004e+00,  6.9595e-01],\n          [-1.7447e-01,  4.1955e-01, -4.7526e-01,  ..., -1.1822e+00,\n           -7.7463e-01, -2.5834e-01],\n          [-5.0080e-03,  5.6665e-02, -1.4874e+00,  ..., -6.8601e-02,\n           -1.1364e+00, -6.3440e-01],\n          ...,\n          [-1.7819e+00,  8.2016e-01,  7.6570e-01,  ...,  6.4133e-01,\n            3.9289e-01, -8.6711e-01],\n          [ 7.1254e-02, -1.2611e-01, -1.7216e-01,  ..., -3.1346e-01,\n            5.4037e-01, -6.9556e-01],\n          [ 7.4675e-01,  9.8331e-01,  2.4603e+00,  ...,  7.0708e-01,\n           -1.7741e+00, -1.1204e+00]]],\n\n\n        [[[-1.6640e+00,  1.3394e+00,  5.6883e-01,  ..., -5.0522e-01,\n           -2.1391e+00,  7.4795e-01],\n          [-2.1475e-01, -7.7169e-01,  2.7602e-01,  ..., -1.1613e+00,\n           -2.2255e+00, -1.1342e+00],\n          [ 3.3120e-01, -2.6405e-01, -1.9710e-01,  ..., -3.4116e-01,\n           -7.0828e-01,  1.8953e-01],\n          ...,\n          [ 1.2297e-01,  8.8065e-01,  1.9716e+00,  ...,  4.6717e-01,\n           -1.4758e+00,  2.8058e-02],\n          [ 5.4719e-01, -6.6383e-01, -1.1155e+00,  ...,  3.8082e-01,\n           -1.7922e+00,  8.7835e-02],\n          [-3.1720e-01,  4.7085e-01, -5.0824e-01,  ...,  1.3602e+00,\n            1.4314e+00,  1.5570e-01]],\n\n         [[-1.2322e-01,  7.4735e-01, -1.7922e+00,  ...,  8.2143e-02,\n            1.4378e+00, -1.2576e+00],\n          [ 1.0349e+00,  1.0921e+00,  1.7887e+00,  ..., -1.5878e-01,\n            4.2459e-01,  9.8674e-01],\n          [ 2.2537e-01,  3.5513e-01,  2.9601e+00,  ...,  4.3510e-01,\n           -1.3818e-01, -1.6869e+00],\n          ...,\n          [-9.3943e-01, -7.0069e-01, -2.5376e+00,  ...,  1.8847e+00,\n            5.5837e-01, -1.4517e+00],\n          [-1.2304e+00,  1.1204e+00, -1.6446e+00,  ..., -3.1502e-01,\n           -8.1386e-01,  1.4414e+00],\n          [ 2.2522e-01, -4.0473e-01,  2.3019e+00,  ...,  7.7937e-01,\n            7.6394e-01,  1.5763e+00]],\n\n         [[-3.3624e-01,  7.8060e-02, -1.3956e+00,  ...,  1.1301e+00,\n            1.6285e+00,  1.4281e+00],\n          [ 1.9485e+00, -2.1698e-01,  1.0105e+00,  ...,  6.9590e-01,\n            1.3078e+00,  8.2056e-01],\n          [-1.5635e-01, -3.5933e-03,  1.9820e+00,  ...,  1.1260e+00,\n            1.1704e+00, -8.8778e-01],\n          ...,\n          [ 6.0621e-02,  2.8595e-01, -9.2034e-01,  ...,  9.0534e-01,\n           -6.6548e-01, -1.2265e+00],\n          [ 6.9856e-01, -2.9778e-01, -7.6314e-01,  ..., -6.6463e-01,\n           -1.1617e+00,  4.6748e-02],\n          [ 1.8759e+00,  7.4821e-01,  2.1183e-01,  ...,  1.6436e+00,\n           -2.0180e-01,  1.2933e-02]],\n\n         ...,\n\n         [[ 1.7344e-01,  3.4437e-01, -6.9946e-01,  ...,  1.0600e+00,\n            1.3491e-02, -5.6704e-01],\n          [-3.2242e-01,  5.8751e-01,  6.8442e-01,  ..., -3.1065e-02,\n            1.5501e+00,  5.8149e-01],\n          [-1.1322e+00, -1.1069e-01,  2.8811e-01,  ...,  7.4595e-01,\n            1.6717e+00,  3.0536e-01],\n          ...,\n          [-6.5017e-01,  1.2289e+00,  2.0194e-01,  ...,  1.8334e-01,\n           -3.5148e-02,  1.2292e-01],\n          [-1.0922e+00,  2.0886e+00, -1.8637e-01,  ..., -8.1074e-01,\n           -4.1975e-01,  3.3889e-01],\n          [-1.4889e-01, -5.4272e-01, -1.1213e+00,  ..., -7.8735e-01,\n           -5.6386e-01,  1.2793e+00]],\n\n         [[ 2.7125e+00, -1.6992e-01, -3.7452e-01,  ...,  6.4411e-01,\n           -1.9950e+00, -8.7863e-01],\n          [ 1.1277e+00, -1.0306e+00,  8.1900e-01,  ..., -5.1816e-01,\n            2.4816e+00, -2.9114e-01],\n          [-1.2479e-01, -4.8211e-01,  1.7400e-01,  ..., -1.4597e+00,\n            5.2010e-01, -1.1900e+00],\n          ...,\n          [ 6.6127e-01, -3.9880e-01,  2.9747e-01,  ...,  3.1825e-02,\n            1.1019e+00, -1.7664e+00],\n          [ 5.9671e-01, -3.1420e-01,  4.1228e-01,  ..., -9.3722e-02,\n           -1.1089e+00, -7.0121e-03],\n          [ 1.1443e-01, -1.8896e+00, -1.9408e+00,  ..., -3.7988e-01,\n            7.4748e-01,  3.2213e-01]],\n\n         [[ 9.4851e-02,  2.6216e-01, -9.7454e-01,  ..., -1.3175e+00,\n            1.3530e+00,  5.5464e-01],\n          [-7.9159e-01, -6.1027e-02, -1.5515e+00,  ..., -1.3305e+00,\n           -5.0728e-01,  7.3792e-02],\n          [ 1.4572e+00, -6.6008e-01,  9.3260e-01,  ...,  5.0429e-01,\n            1.9649e-01, -2.0951e+00],\n          ...,\n          [ 1.0584e+00,  9.8224e-01,  4.8625e-01,  ...,  1.3583e+00,\n            1.6145e-01, -2.4686e+00],\n          [ 8.7927e-01, -5.3675e-01, -1.1116e+00,  ..., -1.8104e-01,\n           -2.0025e-01,  2.1511e-01],\n          [ 1.8609e+00, -2.5303e-01,  1.1687e+00,  ..., -8.7378e-01,\n           -4.8796e-01,  5.9393e-01]]]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# With Learnable Parameters\n",
    "m = nn.BatchNorm2d(100)\n",
    "# Without Learnable Parameters\n",
    "m = nn.BatchNorm2d(100, affine=False)\n",
    "input = torch.randn(20, 100, 35, 45)\n",
    "output = m(input)\n",
    "output"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "forerunner_pytorch",
   "language": "python",
   "display_name": "forerunner_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}